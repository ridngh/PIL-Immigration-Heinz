{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eea63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference : https://python.langchain.com/docs/integrations/llms/huggingface_hub\n",
    "\n",
    "## !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "021f316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d491b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample dataset that has jobs details\n",
    "Jobs = pd.read_csv('./emscad_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27d7bd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>in_balanced_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;h3&gt;We're Food52, and we've created a groundbr...</td>\n",
       "      <td>&lt;p&gt;Food52, a fast-growing, James Beard Award-w...</td>\n",
       "      <td>&lt;ul&gt;\\r\\n&lt;li&gt;Experience with content management...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;h3&gt;90 Seconds, the worlds Cloud Video Product...</td>\n",
       "      <td>&lt;p&gt;Organised - Focused - Vibrant - Awesome!&lt;br...</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;What we expect from you:&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p&gt;Y...</td>\n",
       "      <td>&lt;h3&gt;&lt;b&gt;What you will get from us&lt;/b&gt;&lt;/h3&gt;\\r\\n&lt;...</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;h3&gt;&lt;/h3&gt;\\r\\n&lt;p&gt;Valor Services provides Workfo...</td>\n",
       "      <td>&lt;p&gt;Our client, located in Houston, is actively...</td>\n",
       "      <td>&lt;ul&gt;\\r\\n&lt;li&gt;Implement pre-commissioning and co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Our passion for improving quality of life t...</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;THE COMPANY: ESRI – Environmental System...</td>\n",
       "      <td>&lt;ul&gt;\\r\\n&lt;li&gt;\\r\\n&lt;b&gt;EDUCATION: &lt;/b&gt;Bachelor’s o...</td>\n",
       "      <td>&lt;p&gt;Our culture is anything but corporate—we ha...</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;SpotSource Solutions LLC is a Global Human ...</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;JOB TITLE:&lt;/b&gt; Itemization Review Manage...</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;QUALIFICATIONS:&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;ul&gt;\\r\\n&lt;li&gt;R...</td>\n",
       "      <td>&lt;p&gt;Full Benefits Offered&lt;/p&gt;</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title            location department  \\\n",
       "0                           Marketing Intern    US, NY, New York  Marketing   \n",
       "1  Customer Service - Cloud Video Production      NZ, , Auckland    Success   \n",
       "2    Commissioning Machinery Assistant (CMA)       US, IA, Wever        NaN   \n",
       "3          Account Executive - Washington DC  US, DC, Washington      Sales   \n",
       "4                        Bill Review Manager  US, FL, Fort Worth        NaN   \n",
       "\n",
       "  salary_range                                    company_profile  \\\n",
       "0          NaN  <h3>We're Food52, and we've created a groundbr...   \n",
       "1          NaN  <h3>90 Seconds, the worlds Cloud Video Product...   \n",
       "2          NaN  <h3></h3>\\r\\n<p>Valor Services provides Workfo...   \n",
       "3          NaN  <p>Our passion for improving quality of life t...   \n",
       "4          NaN  <p>SpotSource Solutions LLC is a Global Human ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  <p>Food52, a fast-growing, James Beard Award-w...   \n",
       "1  <p>Organised - Focused - Vibrant - Awesome!<br...   \n",
       "2  <p>Our client, located in Houston, is actively...   \n",
       "3  <p><b>THE COMPANY: ESRI – Environmental System...   \n",
       "4  <p><b>JOB TITLE:</b> Itemization Review Manage...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  <ul>\\r\\n<li>Experience with content management...   \n",
       "1  <p><b>What we expect from you:</b></p>\\r\\n<p>Y...   \n",
       "2  <ul>\\r\\n<li>Implement pre-commissioning and co...   \n",
       "3  <ul>\\r\\n<li>\\r\\n<b>EDUCATION: </b>Bachelor’s o...   \n",
       "4  <p><b>QUALIFICATIONS:</b></p>\\r\\n<ul>\\r\\n<li>R...   \n",
       "\n",
       "                                            benefits telecommuting  \\\n",
       "0                                                NaN             f   \n",
       "1  <h3><b>What you will get from us</b></h3>\\r\\n<...             f   \n",
       "2                                                NaN             f   \n",
       "3  <p>Our culture is anything but corporate—we ha...             f   \n",
       "4                       <p>Full Benefits Offered</p>             f   \n",
       "\n",
       "  has_company_logo has_questions employment_type required_experience  \\\n",
       "0                t             f           Other          Internship   \n",
       "1                t             f       Full-time      Not Applicable   \n",
       "2                t             f             NaN                 NaN   \n",
       "3                t             f       Full-time    Mid-Senior level   \n",
       "4                t             t       Full-time    Mid-Senior level   \n",
       "\n",
       "  required_education                   industry              function  \\\n",
       "0                NaN                        NaN             Marketing   \n",
       "1                NaN  Marketing and Advertising      Customer Service   \n",
       "2                NaN                        NaN                   NaN   \n",
       "3  Bachelor's Degree          Computer Software                 Sales   \n",
       "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "\n",
       "  fraudulent in_balanced_dataset  \n",
       "0          f                   f  \n",
       "1          f                   f  \n",
       "2          f                   f  \n",
       "3          f                   f  \n",
       "4          f                   f  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b2d7630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>Jr. Business Analyst &amp; Quality Analyst (entry...</td>\n",
       "      <td>&lt;p&gt;Duration: Full time / W2&lt;br&gt;&lt;br&gt;Location: P...</td>\n",
       "      <td>US, NJ, PISCATAWAY</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>English Teacher Abroad</td>\n",
       "      <td>&lt;p&gt;Play with kids, get paid for it &lt;/p&gt;\\r\\n&lt;p&gt;...</td>\n",
       "      <td>US, PA, Scranton</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>SQL Server Database Developer Job opportunity ...</td>\n",
       "      <td>&lt;p&gt;&lt;br&gt;&lt;br&gt;Position : SQL Server Database Deve...</td>\n",
       "      <td>US, IL, Barrington</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>Legal Analyst - 12 Month FTC</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;Description&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p&gt;Our mission at...</td>\n",
       "      <td>GB, LND, London</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Part-Time Finance Assistant</td>\n",
       "      <td>&lt;p&gt;Salary:£9 - £10 per hour &lt;br&gt;&lt;br&gt;We are cur...</td>\n",
       "      <td>GB, LND,</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "5736    Jr. Business Analyst & Quality Analyst (entry...   \n",
       "7106                             English Teacher Abroad    \n",
       "11978  SQL Server Database Developer Job opportunity ...   \n",
       "9374                        Legal Analyst - 12 Month FTC   \n",
       "1300                         Part-Time Finance Assistant   \n",
       "\n",
       "                                             description            location  \\\n",
       "5736   <p>Duration: Full time / W2<br><br>Location: P...  US, NJ, PISCATAWAY   \n",
       "7106   <p>Play with kids, get paid for it </p>\\r\\n<p>...   US, PA, Scranton    \n",
       "11978  <p><br><br>Position : SQL Server Database Deve...  US, IL, Barrington   \n",
       "9374   <p><b>Description</b></p>\\r\\n<p>Our mission at...     GB, LND, London   \n",
       "1300   <p>Salary:£9 - £10 per hour <br><br>We are cur...           GB, LND,    \n",
       "\n",
       "      fraudulent  \n",
       "5736           f  \n",
       "7106           f  \n",
       "11978          f  \n",
       "9374           f  \n",
       "1300           f  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample dataset for demo get relevant columns\n",
    "sample= Jobs[['title','description','location','fraudulent']].sample(5,random_state=1)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4930ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function remove HTML tags\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb70fef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>Jr. Business Analyst &amp; Quality Analyst (entry...</td>\n",
       "      <td>Duration: Full time / W2Location: Piscataway,N...</td>\n",
       "      <td>US, NJ, PISCATAWAY</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>English Teacher Abroad</td>\n",
       "      <td>Play with kids, get paid for it \\nLove travel?...</td>\n",
       "      <td>US, PA, Scranton</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>SQL Server Database Developer Job opportunity ...</td>\n",
       "      <td>Position : SQL Server Database DeveloperJob Lo...</td>\n",
       "      <td>US, IL, Barrington</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>Legal Analyst - 12 Month FTC</td>\n",
       "      <td>Description\\nOur mission at MarketInvoice is t...</td>\n",
       "      <td>GB, LND, London</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Part-Time Finance Assistant</td>\n",
       "      <td>Salary:£9 - £10 per hour We are currently goin...</td>\n",
       "      <td>GB, LND,</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "5736    Jr. Business Analyst & Quality Analyst (entry...   \n",
       "7106                             English Teacher Abroad    \n",
       "11978  SQL Server Database Developer Job opportunity ...   \n",
       "9374                        Legal Analyst - 12 Month FTC   \n",
       "1300                         Part-Time Finance Assistant   \n",
       "\n",
       "                                             description            location  \\\n",
       "5736   Duration: Full time / W2Location: Piscataway,N...  US, NJ, PISCATAWAY   \n",
       "7106   Play with kids, get paid for it \\nLove travel?...   US, PA, Scranton    \n",
       "11978  Position : SQL Server Database DeveloperJob Lo...  US, IL, Barrington   \n",
       "9374   Description\\nOur mission at MarketInvoice is t...     GB, LND, London   \n",
       "1300   Salary:£9 - £10 per hour We are currently goin...           GB, LND,    \n",
       "\n",
       "      fraudulent  \n",
       "5736           f  \n",
       "7106           f  \n",
       "11978          f  \n",
       "9374           f  \n",
       "1300           f  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean Description Column\n",
    "sample['description'] = sample['description'].apply(remove_html_tags)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f708ce",
   "metadata": {},
   "source": [
    "### Transformers : Pipeline to scan through job descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad5bb41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bfaba7416e4bab8bf27fcdbd7df966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d6b66389b74a8f92c2f511bac2a59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70c824a1d4b44c5989d786555cfc34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0a076f3ca349308fe41fcff19544bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479e8ae05d28417f987809de1014bda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ab5fb15934492bb43fd97544ae694b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Load the question-answering pipeline\n",
    "qa_pipeline = pipeline('question-answering', model='deepset/roberta-base-squad2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80183079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(input,questions):\n",
    "    answers = []\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"-\" * 30)\n",
    "    for question in questions:\n",
    "        answer = qa_pipeline(question=question, context=input)['answer']\n",
    "        print(question,': ', answer)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1af3ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "------------------------------\n",
      "\"Can minors be employed here\" :  Must be 18 years or older\n",
      " \"Does this provide accomodation\" :  Free Accommodation Options\n",
      " \"Does this have educational requirements\" :  No formal education needed\n"
     ]
    }
   ],
   "source": [
    "#Example: #context = 'Title: Exciting Work-from-Home Opportunity! Earn Big Money Fast! Description: Are you tired of your 9-5 job and looking for a change? We have the perfect opportunity for you! Join our exclusive team and start making money from the comfort of your own home. Key Benefits: No Experience Required! Work Flexible Hours, Part-Time or Full-Time! Earn Up to $10,000 per Month! Quick and Easy Payments via Bitcoin! Requirements: Must be 18 years or older. No formal education needed. No background checks or verifications. Work-at-home kit available for a small fee. Perks: Free Accommodation Options! Travel Opportunities! Exciting Bonuses and Incentives! To apply, simply click the link below and register now! Dont miss out on this once-in-a-lifetime opportunity to change your life! SpammyLink123.com/ApplyNow Note: This is a fictional example and not a real job opportunity. Actual spam job ads may use deceptive language, false promises, or requests for personal information. Always be cautious and thoroughly research any job opportunity before providing personal or financial information'\n",
    "#questions = [\"Can minors be employed here\", \"Does this provide accomodation\", \"Does this have educational requirements\", \"What is the salary range offered in dollars per year format\"]\n",
    " \n",
    "text_to_search = input(\"Enter the text to search: \")\n",
    "questions = input(\"Enter the questions (comma-separated): \").split(',')\n",
    "\n",
    "demo(text_to_search,questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5d72597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Must be 18 years or older', 'Free Accommodation Options', 'No formal education needed', '$10,000 per Month']\n"
     ]
    }
   ],
   "source": [
    "#Demo of how each snippet works\n",
    "\n",
    "# User inputs\n",
    "context = input(\"Enter the text to search: \")\n",
    "questions = input(\"Enter the questions (comma-separated): \").split(',')\n",
    "\n",
    "#context = 'Title: Exciting Work-from-Home Opportunity! Earn Big Money Fast! Description: Are you tired of your 9-5 job and looking for a change? We have the perfect opportunity for you! Join our exclusive team and start making money from the comfort of your own home. Key Benefits: No Experience Required! Work Flexible Hours, Part-Time or Full-Time! Earn Up to $10,000 per Month! Quick and Easy Payments via Bitcoin! Requirements: Must be 18 years or older. No formal education needed. No background checks or verifications. Work-at-home kit available for a small fee. Perks: Free Accommodation Options! Travel Opportunities! Exciting Bonuses and Incentives! To apply, simply click the link below and register now! Dont miss out on this once-in-a-lifetime opportunity to change your life! SpammyLink123.com/ApplyNow Note: This is a fictional example and not a real job opportunity. Actual spam job ads may use deceptive language, false promises, or requests for personal information. Always be cautious and thoroughly research any job opportunity before providing personal or financial information'\n",
    "#questions = [\"Can minors be employed here\", \"Does this provide accomodation\", \"Does this have educational requirements\", \"What is the salary range offered in dollars per year format\"]\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "        answer = qa_pipeline(question=question, context=context)['answer']\n",
    "        answers.append(answer)\n",
    "        \n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c5eecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(row,questions):\n",
    "    context = row['description']\n",
    "    answers = []\n",
    "    for question in questions:\n",
    "        answer = qa_pipeline(question=question, context=context)['answer']\n",
    "        answers.append(answer)\n",
    "\n",
    "    return pd.Series(answers, index=[f'Answer_{i+1}' for i in range(len(questions))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e12834f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try with sample \n",
    "questions = [\"Can minors be employed here\", \"Does this provide accomodation\", \"Does this have educational requirements\", \"What is the salary range offered in dollars per year format\"]\n",
    "\n",
    "sample[['Answer_1', 'Answer_2', 'Answer_3', 'Answer_4']] = sample.apply(lambda row: answer_question(row, questions), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d09d029a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>Answer_1</th>\n",
       "      <th>Answer_2</th>\n",
       "      <th>Answer_3</th>\n",
       "      <th>Answer_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>Jr. Business Analyst &amp; Quality Analyst (entry...</td>\n",
       "      <td>Duration: Full time / W2Location: Piscataway,N...</td>\n",
       "      <td>US, NJ, PISCATAWAY</td>\n",
       "      <td>f</td>\n",
       "      <td>entry level candidates with BA/QA skills are e...</td>\n",
       "      <td>entry level candidates with BA/QA skills are e...</td>\n",
       "      <td>Masters Degree in Computer Science, Engineerin...</td>\n",
       "      <td>Expected Rate / Salary :\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>English Teacher Abroad</td>\n",
       "      <td>Play with kids, get paid for it \\nLove travel?...</td>\n",
       "      <td>US, PA, Scranton</td>\n",
       "      <td>f</td>\n",
       "      <td>\\n12 month contract : Apply today</td>\n",
       "      <td>Housing provided</td>\n",
       "      <td>\\n12 month contract : Apply today</td>\n",
       "      <td>$1,500+ USD monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>SQL Server Database Developer Job opportunity ...</td>\n",
       "      <td>Position : SQL Server Database DeveloperJob Lo...</td>\n",
       "      <td>US, IL, Barrington</td>\n",
       "      <td>f</td>\n",
       "      <td>Candidates should understand and have a proven...</td>\n",
       "      <td>Must be able to manage database objects and da...</td>\n",
       "      <td>BS degree</td>\n",
       "      <td>H1B / EAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>Legal Analyst - 12 Month FTC</td>\n",
       "      <td>Description\\nOur mission at MarketInvoice is t...</td>\n",
       "      <td>GB, LND, London</td>\n",
       "      <td>f</td>\n",
       "      <td>Legal Analyst</td>\n",
       "      <td>This is a unique and very fulfilling role for ...</td>\n",
       "      <td>You will utilise your considerable academic an...</td>\n",
       "      <td>Legal Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Part-Time Finance Assistant</td>\n",
       "      <td>Salary:£9 - £10 per hour We are currently goin...</td>\n",
       "      <td>GB, LND,</td>\n",
       "      <td>f</td>\n",
       "      <td>periods of time when you will be working un-su...</td>\n",
       "      <td>You will offer a flexible, adaptable approach</td>\n",
       "      <td>periods of time when you will be working un-su...</td>\n",
       "      <td>:£9 - £10 per hour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "5736    Jr. Business Analyst & Quality Analyst (entry...   \n",
       "7106                             English Teacher Abroad    \n",
       "11978  SQL Server Database Developer Job opportunity ...   \n",
       "9374                        Legal Analyst - 12 Month FTC   \n",
       "1300                         Part-Time Finance Assistant   \n",
       "\n",
       "                                             description            location  \\\n",
       "5736   Duration: Full time / W2Location: Piscataway,N...  US, NJ, PISCATAWAY   \n",
       "7106   Play with kids, get paid for it \\nLove travel?...   US, PA, Scranton    \n",
       "11978  Position : SQL Server Database DeveloperJob Lo...  US, IL, Barrington   \n",
       "9374   Description\\nOur mission at MarketInvoice is t...     GB, LND, London   \n",
       "1300   Salary:£9 - £10 per hour We are currently goin...           GB, LND,    \n",
       "\n",
       "      fraudulent                                           Answer_1  \\\n",
       "5736           f  entry level candidates with BA/QA skills are e...   \n",
       "7106           f                 \\n12 month contract : Apply today    \n",
       "11978          f  Candidates should understand and have a proven...   \n",
       "9374           f                                      Legal Analyst   \n",
       "1300           f  periods of time when you will be working un-su...   \n",
       "\n",
       "                                                Answer_2  \\\n",
       "5736   entry level candidates with BA/QA skills are e...   \n",
       "7106                                    Housing provided   \n",
       "11978  Must be able to manage database objects and da...   \n",
       "9374   This is a unique and very fulfilling role for ...   \n",
       "1300       You will offer a flexible, adaptable approach   \n",
       "\n",
       "                                                Answer_3  \\\n",
       "5736   Masters Degree in Computer Science, Engineerin...   \n",
       "7106                  \\n12 month contract : Apply today    \n",
       "11978                                          BS degree   \n",
       "9374   You will utilise your considerable academic an...   \n",
       "1300   periods of time when you will be working un-su...   \n",
       "\n",
       "                         Answer_4  \n",
       "5736   Expected Rate / Salary :\\n  \n",
       "7106          $1,500+ USD monthly  \n",
       "11978                   H1B / EAD  \n",
       "9374                Legal Analyst  \n",
       "1300           :£9 - £10 per hour  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f793c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d97bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70f0c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text to search: Title: Exciting Work-from-Home Opportunity! Earn Big Money Fast! Description: Are you tired of your 9-5 job and looking for a change? We have the perfect opportunity for you! Join our exclusive team and start making money from the comfort of your own home. Key Benefits: No Experience Required! Work Flexible Hours, Part-Time or Full-Time! Earn Up to $10,000 per Month! Quick and Easy Payments via Bitcoin! Requirements: Must be 18 years or older. No formal education needed. No background checks or verifications. Work-at-home kit available for a small fee. Perks: Free Accommodation Options! Travel Opportunities! Exciting Bonuses and Incentives! To apply, simply click the link below and register now! Dont miss out on this once-in-a-lifetime opportunity to change your life! SpammyLink123.com/ApplyNow Note: This is a fictional example and not a real job opportunity. Actual spam job ads may use deceptive language, false promises, or requests for personal information. Always be cautious and thoroughly research any job opportunity before providing personal or financial information\n",
      "Enter the questions (comma-separated): What is the salary offered , Are there minors employed here, is accomodation offered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "C:\\Users\\Apoorva Shetty\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1281: UserWarning: Input length of input_ids is 150, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (150) must match the existing size (151) at non-singleton dimension 0.  Target sizes: [150].  Tensor sizes: [151]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[0;32m     22\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_to_search\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 23\u001b[0m     generated_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(generated_response)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with the results\u001b[39;00m\n",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(input_text, max_length)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response\u001b[39m(input_text, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m):\n\u001b[0;32m     10\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39mmax_length, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1752\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1746\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1747\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   1748\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1750\u001b[0m     )\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_search(\n\u001b[0;32m   1753\u001b[0m         input_ids,\n\u001b[0;32m   1754\u001b[0m         beam_scorer,\n\u001b[0;32m   1755\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m   1756\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1757\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[0;32m   1758\u001b[0m         eos_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m   1759\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_scores,\n\u001b[0;32m   1760\u001b[0m         return_dict_in_generate\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1761\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1762\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1763\u001b[0m     )\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE:\n\u001b[0;32m   1766\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:3178\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3175\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3176\u001b[0m             this_peer_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 3178\u001b[0m sequence_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_scorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3179\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3184\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate:\n\u001b[0;32m   3190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_scores:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\beam_search.py:392\u001b[0m, in \u001b[0;36mBeamSearchScorer.finalize\u001b[1;34m(self, input_ids, final_beam_scores, final_beam_tokens, final_beam_indices, max_length, pad_token_id, eos_token_id, beam_indices)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;66;03m# fill with hypotheses and eos_token_id if the latter fits in\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (hypo, best_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(best, best_indices)):\n\u001b[1;32m--> 392\u001b[0m     decoded[i, : sent_lengths[i]] \u001b[38;5;241m=\u001b[39m hypo\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    395\u001b[0m         indices[i, : \u001b[38;5;28mlen\u001b[39m(best_idx)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(best_idx)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (150) must match the existing size (151) at non-singleton dimension 0.  Target sizes: [150].  Tensor sizes: [151]"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import pandas as pd\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Function to generate a response based on the input text\n",
    "def generate_response(input_text, max_length=150):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "    # Ensure that max_length is less than or equal to the length of input_ids\n",
    "    max_length = min(max_length, input_ids.size(1))\n",
    "    outputs = model.generate(input_ids, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# User inputs\n",
    "text_to_search = input(\"Enter the text to search: \")\n",
    "questions = input(\"Enter the questions (comma-separated): \").split(',')\n",
    "\n",
    "# Generate response for each question\n",
    "responses = []\n",
    "for question in questions:\n",
    "    input_text = f\"{text_to_search} Question: {question}\"\n",
    "\n",
    "    # Split input text into smaller chunks (e.g., 150 tokens per chunk)\n",
    "    chunk_size = 150\n",
    "    chunks = [input_text[i:i+chunk_size] for i in range(0, len(input_text), chunk_size)]\n",
    "\n",
    "    # Generate response for each chunk and concatenate the results\n",
    "    chunk_responses = [generate_response(chunk) for chunk in chunks]\n",
    "    responses.append(' '.join(chunk_responses))\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "df = pd.DataFrame({'Question': questions, 'Response': responses})\n",
    "\n",
    "# Parse the generated responses into a categorical column (example: Positive/Negative)\n",
    "df['Category'] = df['Response'].apply(lambda x: 'Positive' if 'positive keyword' in x else 'Negative')\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed41ca17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text to search: Exciting Work-from-Home Opportunity! Earn Big Money Fast! Description: Are you tired of your 9-5 job and looking for a change? We have the perfect opportunity for you! Join our exclusive team and start making money from the comfort of your own home. Key Benefits: No Experience Required! Work Flexible Hours, Part-Time or Full-Time! Earn Up to $10,000 per Month! Quick and Easy Payments via Bitcoin! Requirements: Must be 18 years or older. No formal education needed. No background checks or verifications. Work-at-home kit available for a small fee. Perks: Free Accommodation Options! Travel Opportunities! Exciting Bonuses and Incentives! To apply, simply click the link below and register now! Dont miss out on this once-in-a-lifetime opportunity to change your life! SpammyLink123.com/ApplyNow\n",
      "Enter the questions (comma-separated): What is the salary offered , Are there minors employed here, is accomodation offered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "C:\\Users\\Apoorva Shetty\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1281: UserWarning: Input length of input_ids is 36, but `max_length` is set to 36. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (36) must match the existing size (37) at non-singleton dimension 0.  Target sizes: [36].  Tensor sizes: [37]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m [input_text[i:i\u001b[38;5;241m+\u001b[39mchunk_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(input_text), chunk_size)]\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Generate response for each chunk and concatenate the results\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     chunk_responses \u001b[38;5;241m=\u001b[39m [generate_response(chunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     32\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunk_responses))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with the results\u001b[39;00m\n",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     28\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m [input_text[i:i\u001b[38;5;241m+\u001b[39mchunk_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(input_text), chunk_size)]\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Generate response for each chunk and concatenate the results\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     chunk_responses \u001b[38;5;241m=\u001b[39m [\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     32\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunk_responses))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with the results\u001b[39;00m\n",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(input_text, max_length)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Ensure that max_length is less than or equal to the length of input_ids\u001b[39;00m\n\u001b[0;32m     12\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_length, input_ids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1752\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1746\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1747\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   1748\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1750\u001b[0m     )\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_search(\n\u001b[0;32m   1753\u001b[0m         input_ids,\n\u001b[0;32m   1754\u001b[0m         beam_scorer,\n\u001b[0;32m   1755\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m   1756\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1757\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[0;32m   1758\u001b[0m         eos_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m   1759\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_scores,\n\u001b[0;32m   1760\u001b[0m         return_dict_in_generate\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1761\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1762\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1763\u001b[0m     )\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE:\n\u001b[0;32m   1766\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:3178\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3175\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3176\u001b[0m             this_peer_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 3178\u001b[0m sequence_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_scorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3179\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3184\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate:\n\u001b[0;32m   3190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_scores:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\beam_search.py:392\u001b[0m, in \u001b[0;36mBeamSearchScorer.finalize\u001b[1;34m(self, input_ids, final_beam_scores, final_beam_tokens, final_beam_indices, max_length, pad_token_id, eos_token_id, beam_indices)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;66;03m# fill with hypotheses and eos_token_id if the latter fits in\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (hypo, best_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(best, best_indices)):\n\u001b[1;32m--> 392\u001b[0m     decoded[i, : sent_lengths[i]] \u001b[38;5;241m=\u001b[39m hypo\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    395\u001b[0m         indices[i, : \u001b[38;5;28mlen\u001b[39m(best_idx)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(best_idx)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (36) must match the existing size (37) at non-singleton dimension 0.  Target sizes: [36].  Tensor sizes: [37]"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import pandas as pd\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Function to generate a response based on the input text\n",
    "def generate_response(input_text, max_length=150):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "    # Ensure that max_length is less than or equal to the length of input_ids\n",
    "    max_length = min(max_length, input_ids.size(1))\n",
    "    outputs = model.generate(input_ids, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# User inputs\n",
    "text_to_search = input(\"Enter the text to search: \")\n",
    "questions = input(\"Enter the questions (comma-separated): \").split(',')\n",
    "\n",
    "# Generate response for each question\n",
    "responses = []\n",
    "for question in questions:\n",
    "    input_text = f\"{text_to_search} Question: {question}\"\n",
    "\n",
    "    # Split input text into smaller chunks (e.g., 150 tokens per chunk)\n",
    "    chunk_size = 150\n",
    "    chunks = [input_text[i:i+chunk_size] for i in range(0, len(input_text), chunk_size)]\n",
    "\n",
    "    # Generate response for each chunk and concatenate the results\n",
    "    chunk_responses = [generate_response(chunk) for chunk in chunks]\n",
    "    responses.append(' '.join(chunk_responses))\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "df = pd.DataFrame({'Question': questions, 'Response': responses})\n",
    "\n",
    "# Parse the generated responses into a categorical column (example: Positive/Negative)\n",
    "df['Category'] = df['Response'].apply(lambda x: 'Positive' if 'positive keyword' in x else 'Negative')\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c399f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2695df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e5017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a45b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d56929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fc0c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authentication with HuggingFace\n",
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e26f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a08527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "# Enter Hugging Face API Key\n",
    "from getpass import getpass\n",
    "HUGGINGFACEHUB_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9156a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7417dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What arw the words associated with fradulent job offers\"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31805fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"google/flan-t5-xxl\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "514a4edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Apoorva Shetty\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fradulent job offers are offers for employment that are not genuine. The words associated with fradulent job offers are fake, scam, false, and fraudulent. The answer: false.\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 64}\n",
    ")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aea9750",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
